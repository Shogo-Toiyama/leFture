import shutil
import traceback
from pathlib import Path
from app.core.supabase import get_supabase_client
from app.core.config import JobStatus, BASE_WORK_DIR

# å„ãƒ­ã‚¸ãƒƒã‚¯ã®ã‚¯ãƒ©ã‚¹ã‚’Import
from app.services.logic.transcription import TranscriptionService
# from app.services.logic.segmentation import SegmentationService ... (ä»–ã‚‚åŒæ§˜ã«)

from contents_generation.scripts.llm.llm_unified import UnifiedLLM, CostCollector

async def run_lecture_pipeline(lecture_id: str, storage_path: str):
    supabase = get_supabase_client()
    
    # 1. ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æº–å‚™ (/tmp/lecture_id)
    work_dir = BASE_WORK_DIR / lecture_id
    if work_dir.exists():
        shutil.rmtree(work_dir) # æ®‹éª¸ãŒã‚ã‚Œã°æ¶ˆã™
    work_dir.mkdir(parents=True, exist_ok=True)
    
    # LLMã¨ã‚³ã‚¹ãƒˆè¨ˆç®—æ©Ÿã®åˆæœŸåŒ– (å…¨ã‚¹ãƒ†ãƒƒãƒ—ã§å…±æœ‰)
    llm = UnifiedLLM(provider="gemini")
    collector = CostCollector()

    try:
        # --- PHASE 0: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ---
        _update_status(supabase, lecture_id, JobStatus.DOWNLOADING)
        audio_local_path = work_dir / "input_audio.m4a"
        
        # Supabase Storageã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ('lectures' ãƒã‚±ãƒƒãƒˆã¨ä»®å®š)
        with open(audio_local_path, "wb") as f:
            res = supabase.storage.from_("lecture_assets").download(storage_path)
            f.write(res)

        # --- PHASE 1: æ–‡å­—èµ·ã“ã— & ãƒ¬ãƒ“ãƒ¥ãƒ¼ ---
        _update_status(supabase, lecture_id, JobStatus.TRANSCRIBING)
        transcriber = TranscriptionService(llm, collector)
        transcript_json_path = transcriber.run(audio_local_path, work_dir)
        
        # é€”ä¸­çµŒéã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        _upload_artifact(supabase, lecture_id, transcript_json_path, "transcript.json")


        # --- PHASE 2: Role Classification (ä¾‹) ---
        # _update_status(supabase, lecture_id, JobStatus.REVIEWING)
        # role_classifier = RoleClassificationService(llm, collector)
        # role_classifier.run(work_dir) 
        # ... ä»¥é™ã€æ—¢å­˜ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’é †ç•ªã«å‘¼ã³å‡ºã—ã¦ã„ã ...


        # --- PHASE FINAL: å®Œäº† ---
        _update_status(supabase, lecture_id, JobStatus.COMPLETED)
        
        # ã‚³ã‚¹ãƒˆæƒ…å ±ã®ãƒ­ã‚°å‡ºåŠ›ãªã©
        print(collector.report())

    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        error_msg = f"{str(e)}\n{traceback.format_exc()}"
        print(f"âŒ Job Failed: {error_msg}")
        
        supabase.table("lectures_assets").update({
            "status": JobStatus.ERROR,
            "error_message": error_msg  # DBã«ã‚¨ãƒ©ãƒ¼è©³ç´°åˆ—ã‚’ä½œã£ã¦ãŠãã¨ä¾¿åˆ©
        }).eq("id", lecture_id).execute()

    finally:
        # ãŠæƒé™¤ (Cloud Runã®ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ç¯€ç´„)
        if work_dir.exists():
            shutil.rmtree(work_dir)


# --- Helper Functions ---

def _update_status(supabase, lecture_id: str, status: JobStatus):
    """DBã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°ã™ã‚‹"""
    print(f"ğŸ”„ Status Update: {lecture_id} -> {status}")
    supabase.table("lectures_assets").update({
        "status": status
    }).eq("id", lecture_id).execute()

def _upload_artifact(supabase, lecture_id: str, local_path: Path, remote_filename: str):
    """ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’Supabase Storageã«æˆ»ã™"""
    remote_path = f"{lecture_id}/artifacts/{remote_filename}"
    with open(local_path, "rb") as f:
        supabase.storage.from_("lectures").upload(
            path=remote_path,
            file=f,
            file_options={"upsert": "true"}
        )